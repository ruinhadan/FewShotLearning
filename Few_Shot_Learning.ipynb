{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MiniProject 5-shot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruinhadan/FewShotLearning/blob/main/Few_Shot_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9QA65W9WgUb"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVTuV9i0Tat-",
        "outputId": "6c1b8d2b-075d-4876-f920-b45da5e40047"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpktbgrXrqXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65a2e36-92df-4d19-8084-7999583e16eb"
      },
      "source": [
        "!pip install torchnet"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchnet\n",
            "  Downloading torchnet-0.0.4.tar.gz (23 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchnet) (1.10.0+cu111)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchnet) (1.15.0)\n",
            "Collecting visdom\n",
            "  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n",
            "\u001b[K     |████████████████████████████████| 676 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchnet) (3.10.0.2)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from visdom->torchnet) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom->torchnet) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visdom->torchnet) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom->torchnet) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom->torchnet) (22.3.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from visdom->torchnet) (7.1.2)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visdom->torchnet) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visdom->torchnet) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visdom->torchnet) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visdom->torchnet) (1.24.3)\n",
            "Building wheels for collected packages: torchnet, visdom, torchfile\n",
            "  Building wheel for torchnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchnet: filename=torchnet-0.0.4-py3-none-any.whl size=29741 sha256=aac8f56b7d581cde3058f02d4f9287a38a18b6671b293a6de0b50d96b87175ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/17/b3/86db1d93e9dae198813aa79831b403e4844d67986cf93894b5\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655250 sha256=76ce050978411de7d54662817895b4f0dea9aec8e1a2a57ca1cac2d1fc142f11\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/d1/9b/cde923274eac9cbb6ff0d8c7c72fe30a3da9095a38fd50bbf1\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5710 sha256=8f57759237b3eccd27fce38bd5935b5861a87a19c0ce69ef63739297f00206e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n",
            "Successfully built torchnet visdom torchfile\n",
            "Installing collected packages: jsonpointer, websocket-client, torchfile, jsonpatch, visdom, torchnet\n",
            "Successfully installed jsonpatch-1.32 jsonpointer-2.2 torchfile-0.1.0 torchnet-0.0.4 visdom-0.1.8.9 websocket-client-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR__tOO34aJu"
      },
      "source": [
        "# Imports and Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2U6swyQ3JgN"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import trange\n",
        "import sklearn.metrics as skm\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import torchnet as tnt\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "from PIL import Image\n",
        "from PIL import ImageEnhance\n",
        "import math\n",
        "import random\n",
        "import pickle\n",
        "import collections"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA7N_Sc_R7Ez"
      },
      "source": [
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.cuda.manual_seed(0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8awocDCPt4L"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2tE23UBTW7t"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/MiniImageNet/MiniImagenet/miniImageNet_category_split_train_phase_train.pickle\", 'rb') as f:\n",
        "      ip_data = pickle.load(f, encoding='latin1')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHv807nc5NN4"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4uRYYqA3EcM"
      },
      "source": [
        "class MiniImageNet(data.Dataset):\n",
        "  def __init__(self, data_base, data_novel=None, phase = 'train'):\n",
        "    super(MiniImageNet, self).__init__()\n",
        "\n",
        "    self.data_base = data_base\n",
        "    self.labels = data_base['labels']\n",
        "    self.phase = phase\n",
        "    self.data_novel = data_novel\n",
        "\n",
        "    if self.phase=='train':\n",
        "      self.label2ind = self.buildLabelIndex(self.labels) # {0:[0 to 599], 1:[600 to 1199]...}\n",
        "      self.labelIds = sorted(self.label2ind.keys())      # [0....63]\n",
        "      self.num_cats = len(self.labelIds)                 # 64\n",
        "      self.labelIds_base = self.labelIds                 # [0....63]\n",
        "      self.num_cats_base = len(self.labelIds_base)       # 64\n",
        "      self.data = self.data_base['data']\n",
        "\n",
        "    elif self.phase=='val' or self.phase=='test':          \n",
        "      self.data = np.concatenate([data_base['data'], data_novel['data']], axis=0)\n",
        "      self.labels = data_base['labels'] + data_novel['labels']\n",
        "\n",
        "      self.label2ind = self.buildLabelIndex(self.labels)\n",
        "      self.labelIds = sorted(self.label2ind.keys())\n",
        "      self.num_cats = len(self.labelIds)\n",
        "\n",
        "      self.labelIds_base = self.buildLabelIndex(data_base['labels']).keys()\n",
        "      self.labelIds_novel = self.buildLabelIndex(data_novel['labels']).keys()\n",
        "      self.num_cats_base = len(self.labelIds_base)\n",
        "      self.num_cats_novel = len(self.labelIds_novel)\n",
        "      intersection = set(self.labelIds_base) & set(self.labelIds_novel)\n",
        "      \n",
        "\n",
        "    mean_pix = [x/255.0 for x in [120.39586422,  115.59361427, 104.54012653]]\n",
        "    std_pix = [x/255.0 for x in [70.68188272,  68.27635443,  72.54505529]]\n",
        "    normalize = transforms.Normalize(mean=mean_pix, std=std_pix)\n",
        "\n",
        "    self.transform = transforms.Compose([\n",
        "                    transforms.RandomCrop(84, padding=8),\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    lambda x: np.asarray(x),\n",
        "                    transforms.ToTensor(),\n",
        "                    normalize\n",
        "                ])\n",
        "    \n",
        "    if phase != 'train':\n",
        "      self.transform = transforms.Compose([\n",
        "                    lambda x: np.asarray(x),\n",
        "                    transforms.ToTensor(),\n",
        "                    normalize\n",
        "                ])\n",
        "      \n",
        "  def buildLabelIndex(self, labels):\n",
        "    label2inds = {}\n",
        "    for idx, label in enumerate(labels):\n",
        "        if label not in label2inds:\n",
        "            label2inds[label] = []\n",
        "        label2inds[label].append(idx)\n",
        "\n",
        "    return label2inds\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img, label = self.data[index], self.labels[index]\n",
        "    img = Image.fromarray(img)\n",
        "    img = self.transform(img)\n",
        "    return img, label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_QrO6TV5SX-"
      },
      "source": [
        "# Feature Extractor & Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gscz0cmguwNN"
      },
      "source": [
        "class C128F(nn.Module):\n",
        "    def __init__(self, x_dim=3):\n",
        "        super(C128F, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            self.conv_block(x_dim, 64),\n",
        "            self.conv_block(64, 64),\n",
        "            self.conv_block(64, 128),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    \n",
        "    def conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return x.view(x.size(0), -1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk0KojKAHaiD"
      },
      "source": [
        "class FeatExemplarAvgBlock(nn.Module):\n",
        "    def __init__(self, nFeat):\n",
        "        super(FeatExemplarAvgBlock, self).__init__()\n",
        "\n",
        "    def forward(self, features_train, labels_train):\n",
        "        labels_train_transposed = labels_train.transpose(1,2)\n",
        "        weight_novel = torch.bmm(labels_train_transposed, features_train)\n",
        "        weight_novel = weight_novel.div(\n",
        "            labels_train_transposed.sum(dim=2, keepdim=True).expand_as(weight_novel))\n",
        "        return weight_novel"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zh56rm7Q0ru"
      },
      "source": [
        "class LinearDiag(nn.Module):\n",
        "    def __init__(self, num_features, bias=False):\n",
        "        super(LinearDiag, self).__init__()\n",
        "        weight = torch.FloatTensor(num_features).fill_(1).to(device) # initialize to the identity transform\n",
        "        self.weight = nn.Parameter(weight, requires_grad=True).to(device)\n",
        "\n",
        "        if bias:\n",
        "            bias = torch.FloatTensor(num_features).fill_(0).to(device)\n",
        "            self.bias = nn.Parameter(bias, requires_grad=True).to(device)\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "    def forward(self, X):\n",
        "        assert(X.dim()==2 and X.size(1)==self.weight.size(0))\n",
        "        out = X * self.weight.expand_as(X)\n",
        "        if self.bias is not None:\n",
        "            out = out + self.bias.expand_as(out)\n",
        "        return out"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu_UBZAhlxys"
      },
      "source": [
        "class AttentionBasedBlock(nn.Module):\n",
        "    def __init__(self, nFeat, nK, scale_att=10.0):\n",
        "        super(AttentionBasedBlock, self).__init__()\n",
        "        self.nFeat = nFeat\n",
        "        self.queryLayer = nn.Linear(nFeat, nFeat)\n",
        "        self.queryLayer.weight.data.copy_(torch.eye(nFeat, nFeat) + torch.randn(nFeat, nFeat)*0.001)\n",
        "        self.queryLayer.bias.data.zero_()\n",
        "        scale_att = torch.FloatTensor(1).fill_(scale_att).to(device)\n",
        "        self.scale_att = nn.Parameter(scale_att, requires_grad=True).to(device)\n",
        "        wkeys = torch.FloatTensor(nK, nFeat).normal_(0.0, np.sqrt(2.0/nFeat)).to(device)\n",
        "        self.wkeys = nn.Parameter(wkeys, requires_grad=True).to(device)\n",
        "\n",
        "\n",
        "    def forward(self, features_train, labels_train, weight_base, Kbase):\n",
        "        batch_size, num_train_examples, num_features = features_train.size()\n",
        "        nKbase = weight_base.size(1) # [batch_size x nKbase x num_features]\n",
        "        labels_train_transposed = labels_train.transpose(1,2)\n",
        "        nKnovel = labels_train_transposed.size(1) # [batch_size x nKnovel x num_train_examples]\n",
        "\n",
        "        features_train = features_train.view(\n",
        "            batch_size*num_train_examples, num_features)\n",
        "        Qe = self.queryLayer(features_train)\n",
        "        Qe = Qe.view(batch_size, num_train_examples, self.nFeat)\n",
        "        Qe = F.normalize(Qe, p=2, dim=Qe.dim()-1, eps=1e-12)\n",
        "\n",
        "        wkeys = self.wkeys[Kbase.reshape(-1)] # the keys of the base categoreis\n",
        "        wkeys = F.normalize(wkeys, p=2, dim=wkeys.dim()-1, eps=1e-12)\n",
        "        # Transpose from [batch_size x nKbase x nFeat] to\n",
        "        # [batch_size x self.nFeat x nKbase]\n",
        "        wkeys = wkeys.view(batch_size, nKbase, self.nFeat).transpose(1,2)\n",
        "\n",
        "        # Compute the attention coeficients\n",
        "        # batch matrix multiplications: AttentionCoeficients = Qe * wkeys ==>\n",
        "        # [batch_size x num_train_examples x nKbase] =\n",
        "        #   [batch_size x num_train_examples x nFeat] * [batch_size x nFeat x nKbase]\n",
        "        AttentionCoeficients = self.scale_att * torch.bmm(Qe, wkeys)\n",
        "        AttentionCoeficients = F.softmax(AttentionCoeficients.view(batch_size*num_train_examples, nKbase))\n",
        "        AttentionCoeficients = AttentionCoeficients.view(batch_size, num_train_examples, nKbase)\n",
        "\n",
        "        # batch matrix multiplications: weight_novel = AttentionCoeficients * weight_base ==>\n",
        "        # [batch_size x num_train_examples x num_features] =\n",
        "        #   [batch_size x num_train_examples x nKbase] * [batch_size x nKbase x num_features]\n",
        "        weight_novel = torch.bmm(AttentionCoeficients, weight_base)\n",
        "        # batch matrix multiplications: weight_novel = labels_train_transposed * weight_novel ==>\n",
        "        # [batch_size x nKnovel x num_features] =\n",
        "        #   [batch_size x nKnovel x num_train_examples] * [batch_size x num_train_examples x num_features]\n",
        "        weight_novel = torch.bmm(labels_train_transposed, weight_novel)\n",
        "        weight_novel = weight_novel.div(\n",
        "            labels_train_transposed.sum(dim=2, keepdim=True).expand_as(weight_novel))\n",
        "\n",
        "        return weight_novel"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mamZbE8J87y9"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self, gen_type=None):\n",
        "    super(Classifier, self).__init__()\n",
        "\n",
        "    self.nFeat = 128*5*5 # 3200\n",
        "    self.nKall = 64\n",
        "    self.nKbase = 64 if gen_type is None else 59\n",
        "    self.nKnovel = 5\n",
        "    self.gen_type = gen_type\n",
        "\n",
        "    weight_base = torch.FloatTensor(self.nKall, self.nFeat).normal_(0.0, np.sqrt(2.0/self.nFeat)).to(device) # 64 * 3200\n",
        "    self.weight_base = nn.Parameter(weight_base, requires_grad=True).to(device)\n",
        "    bias = torch.FloatTensor(1).fill_(0).to(device)\n",
        "    self.bias = nn.Parameter(bias, requires_grad=True).to(device) # torch.tensor([0])\n",
        "    scale_cls = torch.FloatTensor(1).fill_(10.0).to(device)\n",
        "    self.scale_cls = nn.Parameter(scale_cls, requires_grad=True).to(device)\n",
        "\n",
        "    if self.gen_type=='feat_avg':\n",
        "\n",
        "      self.favgblock = FeatExemplarAvgBlock(self.nFeat)\n",
        "      self.wnLayerFavg = LinearDiag(self.nFeat, bias=True)\n",
        "    \n",
        "    elif self.gen_type=='attn':\n",
        "\n",
        "      self.favgblock = FeatExemplarAvgBlock(self.nFeat)\n",
        "      self.attblock = AttentionBasedBlock(self.nFeat, self.nKall)\n",
        "      self.wnLayerFavg = LinearDiag(self.nFeat)\n",
        "      self.wnLayerWatt = LinearDiag(self.nFeat)\n",
        "    \n",
        "  def get_classification_weights(self, features_train=None, labels_train=None, Kbase_ids=None, batch_size=8):\n",
        "    Kbase_ids = np.asarray([[i for i in range(64)] for j in range(batch_size)]) if Kbase_ids is None else Kbase_ids\n",
        "    weight_base = self.weight_base[Kbase_ids.reshape(-1)]\n",
        "    #print(Kbase_ids.shape)\n",
        "    weight_base = weight_base.view(batch_size, self.nKbase, -1)\n",
        "\n",
        "    if features_train is None:\n",
        "      return weight_base\n",
        "    \n",
        "    _, num_train_examples, num_channels = features_train.size()\n",
        "    features_train = F.normalize(features_train, p=2, dim=features_train.dim()-1, eps=1e-12)\n",
        "    if self.gen_type == 'feat_avg':\n",
        "      weight_novel_avg = self.favgblock(features_train, labels_train)\n",
        "      weight_novel = self.wnLayerFavg(weight_novel_avg.view(batch_size * self.nKnovel, num_channels))\n",
        "      weight_novel = weight_novel.view(batch_size, self.nKnovel, num_channels)\n",
        "    \n",
        "    elif self.gen_type=='attn':\n",
        "      weight_novel_avg = self.favgblock(features_train, labels_train)\n",
        "      weight_novel_avg = self.wnLayerFavg(weight_novel_avg.view(batch_size * self.nKnovel, num_channels))\n",
        "      weight_base_tmp = F.normalize(weight_base, p=2, dim=weight_base.dim()-1, eps=1e-12)\n",
        "\n",
        "      weight_novel_att = self.attblock(features_train, labels_train, weight_base_tmp, Kbase_ids)\n",
        "      weight_novel_att = self.wnLayerWatt(weight_novel_att.view(batch_size * self.nKnovel, num_channels)      )\n",
        "      weight_novel = weight_novel_avg + weight_novel_att\n",
        "      weight_novel = weight_novel.view(batch_size, self.nKnovel, num_channels)\n",
        "    \n",
        "    w = torch.cat((weight_base,weight_novel),1)\n",
        "    return w   \n",
        "    \n",
        "\n",
        "  def apply_classification_weights(self, features, cls_weights):\n",
        "    features = F.normalize(features, p=2, dim=features.dim()-1, eps=1e-12) # 8 * 1 * 3200\n",
        "    cls_weights = F.normalize(cls_weights, p=2, dim=cls_weights.dim()-1, eps=1e-12) # 8 * 64 * 3200    \n",
        "    cls_scores = self.scale_cls * torch.baddbmm(self.bias.view(1, 1, 1),features, cls_weights.transpose(1,2)) # transpose to 8 * 3200 * 64\n",
        "    # 8 * [1 * 3200 x 3200 * 64 => 1 * 64 + bias]\n",
        "    return cls_scores # 8 * 1 * 64\n",
        "\n",
        "  def forward(self, features_test = None, features_train = None, labels_train=None, Kbase_ids=None, batch_size=8): \n",
        "    self.nKbase = len(Kbase_ids[0]) if Kbase_ids is not None else 64\n",
        "    cls_weights = self.get_classification_weights(features_train, labels_train, Kbase_ids, batch_size)\n",
        "    features_test = features_test.view(batch_size, 1 if features_train is None else len(features_test[0]), self.nFeat) \n",
        "    cls_scores = self.apply_classification_weights(features_test, cls_weights)\n",
        "    \n",
        "    return cls_scores\n",
        "    "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ssrzEVA5bTQ"
      },
      "source": [
        "# Train Stage 1 - Training the feature extractor & base class classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KQzVdni6ESQ"
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "EPOCHS = 100"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G26MhdMz6xo0"
      },
      "source": [
        "input_data = MiniImageNet(ip_data)\n",
        "dataloader = torch.utils.data.DataLoader(input_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55I83EIB8e8J"
      },
      "source": [
        "feature_extractor = C128F().to(device)\n",
        "base_classifier = Classifier().to(device)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYGMelqzKoaC",
        "outputId": "eda0fd51-8049-44ea-c31c-4399700adbf3"
      },
      "source": [
        "feature_extractor.load_state_dict(torch.load(\"/content/drive/MyDrive/MiniImageNet/MiniImagenet/feat_0.00001_150.pth\"))\n",
        "base_classifier.load_state_dict(torch.load(\"/content/drive/MyDrive/MiniImageNet/MiniImagenet/clas_0.00001_150.pth\"))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqURHXXnBHZ7"
      },
      "source": [
        "opt_feat = optim.SGD(feature_extractor.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
        "opt_clas = optim.SGD(base_classifier.parameters(), lr=0.1,  momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
        "lossfn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uBUyvXN6PfT"
      },
      "source": [
        "opt_feat = optim.Adam(feature_extractor.parameters(), lr=0.000001)\n",
        "opt_clas = optim.Adam(base_classifier.parameters(), lr=0.000001)\n",
        "lossfn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfL9NSXS3F6x",
        "outputId": "5a2aa2a6-11f7-4fae-ba87-c704dc9dd4b0"
      },
      "source": [
        "feature_extractor.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C128F(\n",
              "  (encoder): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIUC-5kx-TID",
        "outputId": "e4539b96-7fcf-4ce8-cd02-3470bac41451"
      },
      "source": [
        "loss_per_epoch = []\n",
        "for epoch in trange(EPOCHS):\n",
        "  sum_of_loss = 0.0\n",
        "  for X,Y in dataloader:\n",
        "    X = X.to(device)\n",
        "    Y = torch.tensor(Y).to(device)\n",
        "    opt_feat.zero_grad()\n",
        "    opt_clas.zero_grad()\n",
        "    output = base_classifier(feature_extractor(X))\n",
        "    loss = lossfn(output.view(8, 64), Y)\n",
        "    sum_of_loss += loss.detach()\n",
        "    loss.backward()\n",
        "    opt_feat.step()\n",
        "    opt_clas.step()\n",
        "    del X, Y, output\n",
        "  print(\"Epoch #\"+str(epoch)+\" Loss:\"+str(sum_of_loss.item()/len(dataloader)))\n",
        "  loss_per_epoch.append(sum_of_loss/len(dataloader))\n",
        "  with open('/content/drive/MyDrive/MiniImageNet/loss_t1_SGD.txt', 'a') as f:\n",
        "    f.write('\\n'+str(sum_of_loss.item()/len(dataloader)))\n",
        "    \n",
        "# plt.plot(loss_per_epoch)\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Cross Entropy Loss')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/100 [01:22<2:15:19, 82.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0 Loss:3.3473614501953124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/100 [02:44<2:14:04, 82.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #1 Loss:2.9933424886067708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/100 [04:05<2:12:31, 81.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #2 Loss:2.927745157877604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/100 [05:28<2:11:16, 82.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #3 Loss:2.894186808268229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 5/100 [06:50<2:09:48, 81.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #4 Loss:2.873554890950521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/100 [08:12<2:08:44, 82.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #5 Loss:2.852427978515625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [09:34<2:07:14, 82.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #6 Loss:2.8499788411458336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/100 [10:56<2:05:56, 82.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #7 Loss:2.849950764973958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/100 [12:19<2:04:40, 82.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #8 Loss:2.8431406656901044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 10/100 [13:41<2:03:15, 82.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #9 Loss:2.843577880859375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/100 [15:03<2:01:58, 82.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #10 Loss:2.8409965006510416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/100 [16:26<2:00:43, 82.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #11 Loss:2.843892822265625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/100 [17:47<1:59:09, 82.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #12 Loss:2.8458042399088543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 14/100 [19:10<1:57:58, 82.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #13 Loss:2.8340474446614583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 15/100 [20:32<1:56:39, 82.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #14 Loss:2.8310701497395834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/100 [21:55<1:55:23, 82.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #15 Loss:2.8333758544921874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/100 [23:17<1:53:52, 82.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #16 Loss:2.8320906575520834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "sM18A5kk-urR",
        "outputId": "46793bf1-bf58-439e-a7f1-6107ee049a40"
      },
      "source": [
        "with open('/content/drive/MyDrive/MiniImageNet/loss_t1_SGD.txt', 'r') as f:\n",
        "  loss_per_epoch = f.readlines()\n",
        "\n",
        "loss_per_epoch = [float(x) for x in loss_per_epoch]\n",
        "\n",
        "plt.plot(loss_per_epoch)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Cross Entropy Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2_oFWwu7J_j"
      },
      "source": [
        "# Saving models' weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOt6mawIhwkZ"
      },
      "source": [
        "torch.save(feature_extractor.state_dict(), \"/content/drive/MyDrive/MiniImageNet/MiniImagenet/feat_SGD.pth\")\n",
        "torch.save(base_classifier.state_dict(), \"/content/drive/MyDrive/MiniImageNet/MiniImagenet/clas_SGD.pth\")\n",
        "torch.save(base_classifier.state_dict()['weight_base'], \"/content/drive/MyDrive/MiniImageNet/MiniImagenet/wts_base_SGD.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUNuK3lQXjYd"
      },
      "source": [
        "# Evaluating Feature Extractor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42oXh4rXc_iW",
        "outputId": "b66e03db-01c6-4031-fc85-3bb942c41167"
      },
      "source": [
        "feature_extractor.load_state_dict(torch.load(\"/content/drive/MyDrive/MiniImageNet/MiniImagenet/feat_0.00001_200.pth\"))\n",
        "base_classifier.load_state_dict(torch.load(\"/content/drive/MyDrive/MiniImageNet/MiniImagenet/clas_0.00001_200.pth\"))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1e8XseyW-lC"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/MiniImageNet/MiniImagenet/miniImageNet_category_split_train_phase_test.pickle\", 'rb') as f:\n",
        "      validation_data = pickle.load(f, encoding='latin1')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd98gqCmcqVR"
      },
      "source": [
        "val_data = MiniImageNet(validation_data)\n",
        "val_dataloader = data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npGTaByVZu6a",
        "outputId": "80471014-c404-4b75-fa67-1fedc268c95f"
      },
      "source": [
        "feature_extractor.eval()\n",
        "acc = 0\n",
        "cnt = 0\n",
        "for X,Y in val_dataloader:\n",
        "  X = X.to(device)\n",
        "  Y = Y.to(device)\n",
        "  output = base_classifier(feature_extractor(X))\n",
        "  pred  = torch.argmax(output.view(8,64),dim=1)\n",
        "  acc += skm.accuracy_score(Y.cpu().detach().numpy(),pred.cpu().detach().numpy())\n",
        "  cnt += 1\n",
        "\n",
        "print('Base class accuracy: ', acc/cnt)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base class accuracy:  0.6527604166666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbU7bNYQgk8M"
      },
      "source": [
        "# Train Stage 2 - Training the Few-shot classification weight generator based on feature averaging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czRRtOY5-iYQ"
      },
      "source": [
        "## Defining the dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxSBvKMCgkbG"
      },
      "source": [
        "class FewShotDataloader():\n",
        "    def __init__(self,\n",
        "                 dataset,\n",
        "                 nKnovel=5, # number of novel categories.\n",
        "                 nKbase=-1, # number of base categories.\n",
        "                 nExemplars=5, # number of training examples per novel category.\n",
        "                 nTestNovel=15*5, # number of test examples for all the novel/base categories.\n",
        "                 nTestBase=15*5,  # 3 * nKnovel for train, 15 * nKnovel for test\n",
        "                 batch_size=1, # number of training episodes per batch.\n",
        "                 epoch_size=10, # number of batches per epoch.\n",
        "                 ):\n",
        "\n",
        "        self.dataset = dataset\n",
        "        self.nKnovel = nKnovel\n",
        "        self.nKbase = nKbase if nKbase >= 0 else 64\n",
        "        self.phase = self.dataset.phase\n",
        "        self.nExemplars = nExemplars\n",
        "        self.nTestNovel = nTestNovel\n",
        "        self.nTestBase = nTestBase\n",
        "        self.batch_size = batch_size\n",
        "        self.epoch_size = epoch_size\n",
        "        self.is_eval_mode = (self.phase=='test') or (self.phase=='val')\n",
        "\n",
        "    def sampleImageIdsFrom(self, cat_id, sample_size=5):\n",
        "\n",
        "        return random.sample(self.dataset.label2ind[cat_id], sample_size)\n",
        "\n",
        "    def sampleCategories(self, cat_set, sample_size=5):\n",
        "        \n",
        "        if cat_set=='base':\n",
        "            labelIds = self.dataset.labelIds_base\n",
        "        elif cat_set=='novel':\n",
        "            labelIds = self.dataset.labelIds_novel\n",
        "\n",
        "        assert(len(labelIds) >= sample_size)        # In case number of labels % 5 != 0        \n",
        "        return random.sample(labelIds, sample_size)\n",
        "\n",
        "    def sample_base_and_novel_categories(self, nKbase, nKnovel):\n",
        "        \n",
        "        if self.is_eval_mode:            \n",
        "            Kbase = sorted(self.sampleCategories('base', nKbase))            \n",
        "            Knovel = sorted(self.sampleCategories('novel', nKnovel))\n",
        "        else:            \n",
        "            cats_ids = self.sampleCategories('base', nKnovel+nKbase)            \n",
        "            random.shuffle(cats_ids)\n",
        "            Knovel = sorted(cats_ids[:nKnovel])       # FAKE novel\n",
        "            Kbase = sorted(cats_ids[nKnovel:])        # Remaining base\n",
        "            #print(\"Novel: \",Knovel, \"Base: \", Kbase)\n",
        "\n",
        "        return Kbase, Knovel                          # Class ids\n",
        "\n",
        "    def sample_test_examples_for_base_categories(self, Kbase, nTestBase):\n",
        "        \n",
        "        Tbase = []\n",
        "        if len(Kbase) > 0:\n",
        "            \n",
        "            KbaseIndices = np.random.choice(np.arange(len(Kbase)), size=nTestBase, replace=True)\n",
        "            KbaseIndices, NumImagesPerCategory = np.unique(\n",
        "                KbaseIndices, return_counts=True)\n",
        "\n",
        "            for Kbase_idx, NumImages in zip(KbaseIndices, NumImagesPerCategory):\n",
        "                imd_ids = self.sampleImageIdsFrom(\n",
        "                    Kbase[Kbase_idx], sample_size=NumImages)\n",
        "                Tbase += [(img_id, Kbase_idx) for img_id in imd_ids]\n",
        "\n",
        "        assert(len(Tbase) == nTestBase)\n",
        "\n",
        "        return Tbase\n",
        "\n",
        "    def sample_train_and_test_examples_for_novel_categories(\n",
        "            self, Knovel, nTestNovel, nExemplars, nKbase):\n",
        "        \n",
        "\n",
        "        if len(Knovel) == 0:\n",
        "            return [], []\n",
        "\n",
        "        nKnovel = len(Knovel)\n",
        "        Tnovel = []\n",
        "        Exemplars = []\n",
        "        assert((nTestNovel % nKnovel) == 0)\n",
        "        nEvalExamplesPerClass = nTestNovel // nKnovel\n",
        "\n",
        "        for Knovel_idx in range(len(Knovel)):\n",
        "            imd_ids = self.sampleImageIdsFrom(\n",
        "                Knovel[Knovel_idx],\n",
        "                sample_size=(nEvalExamplesPerClass + nExemplars))\n",
        "\n",
        "            imds_tnovel = imd_ids[:nEvalExamplesPerClass]\n",
        "            imds_ememplars = imd_ids[nEvalExamplesPerClass:]\n",
        "\n",
        "            Tnovel += [(img_id, nKbase + Knovel_idx) for img_id in imds_tnovel]\n",
        "            Exemplars += [(img_id, nKbase + Knovel_idx) for img_id in imds_ememplars]\n",
        "        assert(len(Tnovel) == nTestNovel)\n",
        "        assert(len(Exemplars) == len(Knovel) * nExemplars)\n",
        "        random.shuffle(Exemplars)\n",
        "\n",
        "        return Tnovel, Exemplars\n",
        "\n",
        "    def sample_episode(self):\n",
        "       \n",
        "        nKnovel = self.nKnovel\n",
        "        nKbase = self.nKbase\n",
        "        nTestNovel = self.nTestNovel\n",
        "        nTestBase = self.nTestBase\n",
        "        nExemplars = self.nExemplars\n",
        "\n",
        "        Kbase, Knovel = self.sample_base_and_novel_categories(nKbase, nKnovel)\n",
        "        Tbase = self.sample_test_examples_for_base_categories(Kbase, nTestBase)\n",
        "        Tnovel, Exemplars = self.sample_train_and_test_examples_for_novel_categories(\n",
        "            Knovel, nTestNovel, nExemplars, nKbase)\n",
        "\n",
        "       \n",
        "        Test = Tbase + Tnovel\n",
        "        random.shuffle(Test)\n",
        "        Kall = Kbase + Knovel\n",
        "\n",
        "        return Exemplars, Test, Kall, nKbase              # Exemplars - 5-way 5-shot, Test - 15 + 15, Kall - shuffle[0...63], nKbase - 59\n",
        "\n",
        "    def createExamplesTensorData(self, examples):\n",
        "        \n",
        "        images = torch.stack(\n",
        "            [self.dataset[img_idx][0] for img_idx, _ in examples], dim=0)\n",
        "        labels = torch.LongTensor([label for _, label in examples])\n",
        "        return images, labels\n",
        "\n",
        "    def get_iterator(self, epoch=0):\n",
        "        rand_seed = epoch\n",
        "        random.seed(rand_seed)\n",
        "        np.random.seed(rand_seed)\n",
        "        def load_function(iter_idx):\n",
        "            Exemplars, Test, Kall, nKbase = self.sample_episode()\n",
        "            Xt, Yt = self.createExamplesTensorData(Test)\n",
        "            Kall = torch.LongTensor(Kall)\n",
        "            if len(Exemplars) > 0:\n",
        "                Xe, Ye = self.createExamplesTensorData(Exemplars)\n",
        "                return Xe, Ye, Xt, Yt, Kall, nKbase\n",
        "            else:\n",
        "                return Xt, Yt, Kall, nKbase\n",
        "\n",
        "        tnt_dataset = tnt.dataset.ListDataset(\n",
        "            elem_list=range(self.epoch_size), load=load_function)\n",
        "        data_loader = tnt_dataset.parallel(\n",
        "            batch_size=self.batch_size,\n",
        "            # num_workers=(0 if self.is_eval_mode else self.num_workers),\n",
        "            shuffle=(False if self.is_eval_mode else True))\n",
        "\n",
        "        return data_loader\n",
        "\n",
        "    def __call__(self, epoch=0):\n",
        "        return self.get_iterator(epoch)\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.epoch_size / self.batch_size)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_ywypBD-v8r"
      },
      "source": [
        "Sample episode\n",
        "```\n",
        "torch.Size([8, 25, 3, 84, 84]) - Xe\n",
        "torch.Size([8, 25]) - Ye\n",
        "torch.Size([8, 30, 3, 84, 84]) - Xt\n",
        "torch.Size([8, 30]) - Yt\n",
        "torch.Size([8, 64]) - Kall\n",
        "torch.Size([8]) - nKbase\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuCrwjgr-vyx"
      },
      "source": [
        "## Instantiating classifier & loading base weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mBI4_wsixlz"
      },
      "source": [
        "input_data = MiniImageNet(ip_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY2Ay1Wa0-HR"
      },
      "source": [
        "dataloader = FewShotDataloader(\n",
        "    input_data, \n",
        "    nKnovel=5, \n",
        "    nKbase=59, \n",
        "    nExemplars=5, \n",
        "    nTestNovel=15, \n",
        "    nTestBase=15, \n",
        "    batch_size=8, \n",
        "    epoch_size=800\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VekyfkMp5Va",
        "outputId": "7bfffb9c-3866-4950-ced0-6f170366d6ca"
      },
      "source": [
        "feature_extractor = C128F().to(device)\n",
        "feature_extractor.load_state_dict(torch.load('/content/drive/MyDrive/MiniImageNet/MiniImagenet/feat_0.0001_200.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs4KFSF2G0FB"
      },
      "source": [
        "few_shot_classifier = Classifier(gen_type=\"attn\").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95ucQMrXUxbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0964d19e-6a7d-4441-fccb-496024f8f8c5"
      },
      "source": [
        "few_shot_classifier_dict = few_shot_classifier.state_dict()\n",
        "base_classifier_wts = torch.load('/content/drive/MyDrive/MiniImageNet/MiniImagenet/clas_0.0001.pth')\n",
        "modified_state_dict = {}\n",
        "for k in few_shot_classifier_dict.keys():\n",
        "  if k in base_classifier_wts.keys():\n",
        "    modified_state_dict[k] = base_classifier_wts[k]\n",
        "  else:\n",
        "    modified_state_dict[k] = few_shot_classifier_dict[k]\n",
        "modified_state_dict = collections.OrderedDict(modified_state_dict)\n",
        "few_shot_classifier_dict.update(modified_state_dict)\n",
        "few_shot_classifier.load_state_dict(few_shot_classifier_dict)\n",
        "few_shot_classifier.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight_base',\n",
              "              tensor([[ 0.0442,  0.1156,  0.0272,  ..., -0.0061, -0.0129,  0.0302],\n",
              "                      [ 0.0823,  0.1109,  0.0731,  ...,  0.0195,  0.0213, -0.0029],\n",
              "                      [ 0.0269,  0.0225,  0.0528,  ...,  0.1251,  0.1220, -0.0510],\n",
              "                      ...,\n",
              "                      [-0.1039, -0.1648, -0.1487,  ...,  0.0539,  0.0338,  0.0795],\n",
              "                      [ 0.0023,  0.1287,  0.0958,  ...,  0.0716,  0.1468,  0.1630],\n",
              "                      [ 0.0049,  0.0388,  0.0630,  ...,  0.0174, -0.0111, -0.0681]],\n",
              "                     device='cuda:0')),\n",
              "             ('bias', tensor([-2.4290], device='cuda:0')),\n",
              "             ('scale_cls', tensor([44.0892], device='cuda:0')),\n",
              "             ('attblock.scale_att', tensor([10.], device='cuda:0')),\n",
              "             ('attblock.wkeys',\n",
              "              tensor([[-0.0313,  0.0350,  0.0308,  ...,  0.0114, -0.0255,  0.0478],\n",
              "                      [-0.0146, -0.0135,  0.0034,  ..., -0.0427,  0.0055, -0.0198],\n",
              "                      [-0.0030, -0.0296, -0.0339,  ..., -0.0168, -0.0044, -0.0177],\n",
              "                      ...,\n",
              "                      [ 0.0032, -0.0044,  0.0123,  ...,  0.0059, -0.0242,  0.0088],\n",
              "                      [ 0.0043,  0.0189, -0.0453,  ...,  0.0265,  0.0368,  0.0125],\n",
              "                      [-0.0020, -0.0139,  0.0231,  ...,  0.0089,  0.0374,  0.0054]],\n",
              "                     device='cuda:0')),\n",
              "             ('attblock.queryLayer.weight',\n",
              "              tensor([[ 1.0002e+00, -9.7677e-04, -1.3877e-03,  ..., -9.5072e-04,\n",
              "                        3.7559e-04,  1.4088e-03],\n",
              "                      [ 1.4559e-03,  9.9994e-01, -1.5635e-03,  ...,  1.2086e-03,\n",
              "                        3.6496e-04,  5.1539e-04],\n",
              "                      [ 1.4857e-03,  2.3890e-03,  9.9809e-01,  ...,  1.2763e-03,\n",
              "                       -2.0852e-05, -7.8972e-04],\n",
              "                      ...,\n",
              "                      [ 1.6915e-03,  7.1993e-04, -2.3017e-03,  ...,  9.9975e-01,\n",
              "                        4.9578e-04, -7.3915e-04],\n",
              "                      [-1.3080e-04, -2.1324e-04,  3.1213e-04,  ...,  2.4104e-04,\n",
              "                        1.0012e+00,  2.8899e-04],\n",
              "                      [ 7.8584e-04,  1.1508e-03,  5.2367e-04,  ..., -7.5529e-04,\n",
              "                       -4.8490e-04,  9.9959e-01]], device='cuda:0')),\n",
              "             ('attblock.queryLayer.bias',\n",
              "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')),\n",
              "             ('wnLayerFavg.weight',\n",
              "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
              "             ('wnLayerWatt.weight',\n",
              "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXhG89IvnJmu"
      },
      "source": [
        "opt_clas = optim.Adam(few_shot_classifier.parameters(), lr=0.0001)\n",
        "lossfn = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD1hXv0X9_jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04bcc423-571b-4f50-d95c-3583db6a94a9"
      },
      "source": [
        "EPOCHS=100\n",
        "\n",
        "loss_per_epoch = []\n",
        "feature_extractor.eval()\n",
        "\n",
        "for param in feature_extractor.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "for epoch in trange(EPOCHS):\n",
        "  sum_of_loss = 0.0\n",
        "\n",
        "  for Xe,Ye,Xt,Yt,Kall,nKbase in dataloader():\n",
        "    Xe = Xe.to(device).view(8 * 25, 3, 84, 84)\n",
        "    features_train = feature_extractor(Xe)\n",
        "    features_train = features_train.resize(8,25,3200)\n",
        "    del Xe\n",
        "\n",
        "    Xt = Xt.to(device).view(8 * 30, 3, 84, 84)\n",
        "    features_test = feature_extractor(Xt)\n",
        "    features_test = features_test.resize(8,30,3200)\n",
        "    Ye = torch.tensor(Ye).to(device)\n",
        "    labels_train = []\n",
        "\n",
        "    for labels in Ye:\n",
        "      enc = OneHotEncoder()\n",
        "      labels_train.append(enc.fit_transform(labels.cpu().numpy().reshape(-1,1)).toarray())\n",
        "\n",
        "    labels_train = torch.tensor(labels_train).to(device)\n",
        "\n",
        "    opt_clas.zero_grad()\n",
        "\n",
        "    output = few_shot_classifier(features_test, features_train.float(), labels_train.float(), Kbase_ids=Kall[:,:59], batch_size=8)\n",
        "    \n",
        "    Yt = torch.tensor(Yt).to(device).view(8*30)\n",
        "    loss = lossfn(output.view(8*30,64), Yt)\n",
        "    sum_of_loss+=loss.detach()\n",
        "\n",
        "    loss.backward()    \n",
        "    opt_clas.step()\n",
        "\n",
        "  print(\"Epoch #\"+str(epoch)+\" Loss:\"+str(sum_of_loss.item()/100))  \n",
        "  loss_per_epoch.append(sum_of_loss/100)\n",
        "  with open('/content/drive/MyDrive/MiniImageNet/loss_t2_attn_0.0001.txt', 'a') as f:\n",
        "    f.write('\\n'+str(sum_of_loss.item()/100))\n",
        "    \n",
        "# plt.plot(loss_per_epoch)\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Cross Entropy Loss')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/100 [00:43<1:11:06, 43.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0 Loss:1.1465919494628907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/100 [01:25<1:10:09, 42.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #1 Loss:1.0857844543457031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/100 [02:08<1:09:22, 42.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #2 Loss:1.058219223022461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/100 [02:51<1:08:24, 42.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #3 Loss:1.0243619537353517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 5/100 [03:33<1:07:37, 42.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #4 Loss:1.0150029754638672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/100 [04:16<1:06:51, 42.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #5 Loss:1.0014380645751952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [04:58<1:05:57, 42.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #6 Loss:0.9799132537841797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/100 [05:41<1:05:11, 42.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #7 Loss:0.9687138366699218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/100 [06:23<1:04:31, 42.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #8 Loss:0.9636550903320312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 10/100 [07:06<1:03:52, 42.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #9 Loss:0.9547669219970704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/100 [07:49<1:03:15, 42.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #10 Loss:0.9435520935058593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/100 [08:31<1:02:27, 42.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #11 Loss:0.9383528900146484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/100 [09:14<1:01:43, 42.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #12 Loss:0.9296582794189453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 14/100 [09:56<1:01:01, 42.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #13 Loss:0.9186029052734375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 15/100 [10:39<1:00:17, 42.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #14 Loss:0.9169963836669922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/100 [11:22<59:38, 42.60s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #15 Loss:0.8995966339111328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/100 [12:04<58:59, 42.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #16 Loss:0.8992731475830078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 18/100 [12:47<58:16, 42.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #17 Loss:0.8932193756103516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 19/100 [13:30<57:41, 42.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #18 Loss:0.8842625427246094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 20/100 [14:13<57:00, 42.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #19 Loss:0.8848774719238282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/100 [14:56<56:19, 42.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #20 Loss:0.8749813842773437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/100 [15:38<55:30, 42.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #21 Loss:0.8780233001708985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 23/100 [16:21<54:46, 42.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #22 Loss:0.8627275085449219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 24/100 [17:04<54:06, 42.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #23 Loss:0.8624803161621094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 25/100 [17:46<53:19, 42.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #24 Loss:0.8527590942382812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 26/100 [18:29<52:35, 42.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #25 Loss:0.8502377319335938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 27/100 [19:11<51:49, 42.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #26 Loss:0.8443107604980469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 28/100 [19:54<51:07, 42.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #27 Loss:0.8371894073486328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 29/100 [20:37<50:28, 42.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #28 Loss:0.8409717559814454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 30/100 [21:19<49:40, 42.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #29 Loss:0.838304672241211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 31/100 [22:01<48:54, 42.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #30 Loss:0.8292378234863281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 32/100 [22:44<48:10, 42.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #31 Loss:0.8281447601318359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 33/100 [23:26<47:23, 42.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #32 Loss:0.816662826538086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 34/100 [24:09<46:40, 42.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #33 Loss:0.8251645660400391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 35/100 [24:51<45:54, 42.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #34 Loss:0.814389419555664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 36/100 [25:33<45:11, 42.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #35 Loss:0.8101661682128907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 37/100 [26:16<44:29, 42.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #36 Loss:0.8083081817626954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 38/100 [26:58<43:49, 42.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #37 Loss:0.8032029724121094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 39/100 [27:40<43:07, 42.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #38 Loss:0.8076356506347656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 40/100 [28:23<42:29, 42.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #39 Loss:0.800742416381836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 41/100 [29:06<41:52, 42.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #40 Loss:0.8036363983154297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 42/100 [29:49<41:13, 42.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #41 Loss:0.7943238830566406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 43/100 [30:31<40:29, 42.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #42 Loss:0.7835118865966797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 44/100 [31:14<39:49, 42.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #43 Loss:0.790740966796875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 45/100 [31:57<39:04, 42.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #44 Loss:0.7855281829833984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 46/100 [32:39<38:18, 42.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #45 Loss:0.7836209106445312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 47/100 [33:22<37:35, 42.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #46 Loss:0.7762865447998046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 48/100 [34:04<36:50, 42.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #47 Loss:0.7773297882080078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 49/100 [34:46<36:02, 42.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #48 Loss:0.7771942901611328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 50/100 [35:28<35:17, 42.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #49 Loss:0.7683669281005859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 51/100 [36:10<34:32, 42.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #50 Loss:0.7746745300292969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 52/100 [36:53<33:48, 42.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #51 Loss:0.771399917602539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 53/100 [37:35<33:05, 42.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #52 Loss:0.7660927581787109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 54/100 [38:17<32:24, 42.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #53 Loss:0.7589009857177734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 55/100 [39:00<31:43, 42.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #54 Loss:0.7586592102050781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 56/100 [39:42<31:03, 42.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #55 Loss:0.7622734069824219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 57/100 [40:24<30:20, 42.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #56 Loss:0.7505474853515625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 58/100 [41:07<29:39, 42.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #57 Loss:0.7526702117919922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 59/100 [41:49<28:55, 42.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #58 Loss:0.7572760772705078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 60/100 [42:31<28:13, 42.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #59 Loss:0.7531883239746093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 61/100 [43:14<27:32, 42.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #60 Loss:0.7414000701904296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 62/100 [43:56<26:50, 42.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #61 Loss:0.7464344024658203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 63/100 [44:39<26:11, 42.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #62 Loss:0.7437579345703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 64/100 [45:22<25:31, 42.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #63 Loss:0.7501676940917968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 65/100 [46:04<24:49, 42.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #64 Loss:0.7460569763183593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 66/100 [46:47<24:10, 42.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #65 Loss:0.7352407836914062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 67/100 [47:30<23:29, 42.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #66 Loss:0.7360650634765625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 68/100 [48:13<22:44, 42.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #67 Loss:0.7355065155029297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 69/100 [48:55<21:58, 42.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #68 Loss:0.7361734771728515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 70/100 [49:37<21:14, 42.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #69 Loss:0.7305329895019531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 71/100 [50:19<20:28, 42.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #70 Loss:0.7296633148193359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 72/100 [51:02<19:47, 42.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #71 Loss:0.7235158538818359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 73/100 [51:44<19:03, 42.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #72 Loss:0.7282904052734375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 74/100 [52:26<18:21, 42.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #73 Loss:0.7253614044189454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 75/100 [53:09<17:41, 42.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #74 Loss:0.7209054565429688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 76/100 [53:52<17:00, 42.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #75 Loss:0.7236116790771484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 77/100 [54:34<16:16, 42.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #76 Loss:0.7200167846679687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 78/100 [55:16<15:33, 42.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #77 Loss:0.716713638305664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 79/100 [55:59<14:51, 42.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #78 Loss:0.7192257690429688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 80/100 [56:42<14:10, 42.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #79 Loss:0.7153083801269531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 81/100 [57:24<13:29, 42.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #80 Loss:0.7108322906494141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 82/100 [58:07<12:47, 42.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #81 Loss:0.7092552185058594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 83/100 [58:50<12:05, 42.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #82 Loss:0.7116793823242188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 84/100 [59:33<11:24, 42.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #83 Loss:0.7079996490478515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 85/100 [1:00:16<10:43, 42.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #84 Loss:0.7091478729248046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 86/100 [1:00:59<10:01, 42.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #85 Loss:0.708238525390625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 87/100 [1:01:42<09:19, 43.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #86 Loss:0.7018488311767578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 88/100 [1:02:25<08:35, 42.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #87 Loss:0.7035836791992187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 89/100 [1:03:08<07:51, 42.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #88 Loss:0.7045451354980469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 90/100 [1:03:50<07:07, 42.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #89 Loss:0.6965798950195312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 91/100 [1:04:33<06:24, 42.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #90 Loss:0.6964947509765625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 92/100 [1:05:16<05:42, 42.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #91 Loss:0.6916747283935547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 93/100 [1:05:59<05:00, 42.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #92 Loss:0.694790267944336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 94/100 [1:06:42<04:17, 42.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #93 Loss:0.6976782989501953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 95/100 [1:07:25<03:33, 42.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #94 Loss:0.6907790374755859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 96/100 [1:08:07<02:51, 42.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #95 Loss:0.6965191650390625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 97/100 [1:08:50<02:08, 42.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #96 Loss:0.6895405578613282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 98/100 [1:09:32<01:25, 42.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #97 Loss:0.6900896453857421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 99/100 [1:10:15<00:42, 42.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #98 Loss:0.6885320281982422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [1:10:57<00:00, 42.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #99 Loss:0.6912133026123047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "VpWyEmuK8Jfc",
        "outputId": "03a548df-ca21-4f24-b956-570a992ffbd9"
      },
      "source": [
        "with open('/content/drive/MyDrive/MiniImageNet/loss_t2_attn_0.0001.txt', 'r') as f:\n",
        "  loss_per_epoch = f.readlines()\n",
        "\n",
        "loss_per_epoch = [float(x) for x in loss_per_epoch]\n",
        "\n",
        "plt.plot(loss_per_epoch)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Cross Entropy Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV9f3H8dcnN5MkJJDEAAkbBNkCylAranFX6x5Uq1Wp/lxddvy6tK1t7U9t66iKSh111OKiotYtxQnI3hvCngkz8/P7414wIuMi3Jwk5/18PO6De0bu/Zwem3fO93vO92vujoiIhFdS0AWIiEiwFAQiIiGnIBARCTkFgYhIyCkIRERCLjnoAg5Ufn6+t2vXLugyREQalIkTJ65z94I9bWtwQdCuXTsmTJgQdBkiIg2KmS3Z2zY1DYmIhJyCQEQk5BQEIiIhpyAQEQk5BYGISMgpCEREQk5BICIScqEJgtmryvjT67Mp3VYZdCkiIvVKaIJg6fpt/O29BSzdsC3oUkRE6pXQBEGr3AwAlm/aHnAlIiL1S2iCoCgWBCsUBCIiXxCaIMhtkkJGSkRBICKym9AEgZnRKjedFaUKAhGR2kITBBDtJ1i+aUfQZYiI1CuhCoKi3Aw1DYmI7CZUQdAqN4O1m8spr6oOuhQRkXojdEEAsKpUzUMiIjuFLAjSAT1LICJSW6iC4PNnCXRFICKyU6iCoEVO9IpAHcYiIp8LVRCkJUcoyE5TEIiI1BKqIICdzxIoCEREdgpdEBTlpuuKQESkltAFQaucDFZs2oG7B12KiEi9EL4gyM1ge2U1mzRBjYgIkMAgMLORZrbGzKbvZXtXM/vIzMrN7EeJqmN3mpdAROSLEnlF8Bhw6j62bwBuAu5MYA1fonkJRES+KGFB4O5jif6y39v2Ne4+HqjTNpqdTxcrCEREohpEH4GZDTezCWY2Ye3atQf1Wc0zU0lLTmKFxhsSEQEaSBC4+wh37+/u/QsKCg7qs6IT1OhZAhGRnRpEEBxqrfQsgYjILuEMghxNUCMislNyoj7YzJ4BhgD5ZlYC/BpIAXD3B82sBTABaArUmNn3gG7uXpaomnZqlZvBms3lVFTVkJocyiwUEdklYUHg7pfsZ/sqoDhR378vRbkZuMPqsh20bt4kiBJEROqNUP45XNw8+izBgrVbAq5ERCR4oQyC3sW5JCcZnyza62MOIiKhEcogyExLpk/rXD5csD7oUkREAhfKIAAY3CmfaSWbKNuhwedEJNzCGwQd86hx+HShmodEJNxCGwRHtsklLTmJDxasC7oUEZFAhTYI0pIjHNWuOR+pn0BEQi60QQAwqGMes1dtZt2W8qBLEREJTKiDYHDHPAA+XqirAhEJr1AHQc+iHLLTknUbqYiEWqiDIDmSxIAO6icQkXALdRAADOqYz6J1WzUaqYiEloKgQ7Sf4JNFuioQkXAKfRB0aZFNk9QIU5aVBl2KiEggQh8EkSSjR6scppRsCroUEZFAhD4IAHq3zmHGijIqqmqCLkVEpM4pCIDerXOpqKphzqrNQZciIlLnFARE5ycA1DwkIqGkIACKm2WQl5nKlGUKAhEJHwUBYGb0bp2rKwIRCSUFQUzv4lzmrdnClvKqoEsREalTCoKYXq1zcIdpJXqeQETCRUEQow5jEQkrBUFM88xU2jRvog5jEQkdBUEtvVvnKghEJHQUBLX0Ls5hRekO1mzeEXQpIiJ1RkFQS5/W0X6C8Ys2BlyJiEjdURDU0rM4h7Z5TfjtKzNZr3mMRSQk9hsEZpZpZkmx94eb2VlmlpL40upeWnKEvw3ry4ZtFXzvn5OprvGgSxIRSbh4rgjGAulmVgS8AVwGPJbIooLUvVUOt53Vnf/OW8e978wLuhwRkYSLJwjM3bcB5wJ/c/cLgO6JLStYFx/VmnOPLOKvb8/TfMYi0ujFFQRmNggYBoyJrYskrqTgmRm/O6cHxc0y+N2YmdSoiUhEGrF4guB7wM+AF919hpl1AN5NbFnBa5KazA+GHs6MFWW8Nn1V0OWIiCTMfoPA3d9397Pc/Y5Yp/E6d7+pDmoL3Fm9izi8MIu73pxDVbVmLxORximeu4aeNrOmZpYJTAdmmtktcfzcSDNbY2bT97LdzOweM5tvZlPNrO+Bl59YkSTjhyd3YeHarbzw2fKgyxERSYh4moa6uXsZ8E3gNaA90TuH9ucx4NR9bD8N6Bx7DQceiOMz69zJ3Qrp3TqXv7w1lx2V1UGXIyJyyMUTBCmx5wa+CYx290pgv72n7j4W2LCPXc4GnvCoj4FcM2sZT9F1ycz48SldWFG6g3+OXxZ0OSIih1w8QfAQsBjIBMaaWVug7BB8dxFQ+zdrSWxdvXNMp3x6FDXlhUlqHhKRxieezuJ73L3I3U+P/fW+BDihDmrbxcyGm9kEM5uwdu3auvzqXU7v2ZIpyzZRsnFbIN8vIpIo8XQW55jZ3Tt/EZvZXUSvDg7WcqB1reXi2LovcfcR7t7f3fsXFBQcgq8+cKf3iLZava5bSUWkkYmnaWgksBm4MPYqA/5+CL57NHB57O6hgUCpu688BJ+bEO3yM+nWsiljptXbEkVEvpLkOPbp6O7n1Vq+zcwm7++HzOwZYAiQb2YlwK+BFAB3fxB4FTgdmA9sA648sNLr3hm9WvJ//5nDik3baZWbEXQ5IiKHRDxBsN3MjnX3cQBmdgywfX8/5O6X7Ge7A9fHVWU9cXrPaBC8Nn0VVx3bPuhyREQOiXiahq4F7jezxWa2GLgP+G5Cq6qn2udnckTLpryq5iERaUTiuWtoirv3BnoBvdz9SODEhFdWT53eowUTl2xkZel+L4pERBqEuGcoc/ey2BPGAD9IUD313um9oncPvTpNdw+JSOPwVaeqtENaRQPSsSCLPq1zefD9BZRurwy6HBGRg/ZVgyDUA/T/9uwerN9Szh9fmx10KSIiB22vQWBmm82sbA+vzUCrOqyx3ulZnMNVx7bnmU+X8slCzWAmIg3bXoPA3bPdvekeXtnuHs9tp43a94ceTnGzDH724jTKqzQqqYg0XF+1aSj0mqQmc/s5PVm4diu3/XsmlZq4RkQaKAXBQTj+8AKuPrY9T3+ylPMf+JBF67YGXZKIyAFTEBykX5zZjb8N68vi9ds4457/8vJkDVUtIg1LPKOP3mhmzeqimIbq9J4tef17x9GjVQ4/fG6KOpBFpEGJ54qgEBhvZs+Z2almFtpnCPalZU4Gj1zRnzZ5Tfifpz5jxSY9eSwiDUM8Q0z8gui8wo8CVwDzzOz3ZtYxwbU1OE3TUxhxWX/Kq2r47pMTNcexiDQIcfURxEYKXRV7VQHNgFFm9qcE1tYgdTosiz9f1Idpy0v51cvTgy5HRGS/4ukjuNnMJgJ/Aj4Aerr7dUA/4Lx9/nBIDe1WyPUndOS5CSW8PzeYqTVFROIVzxVBc+Bcdz/F3f/l7pUA7l4DnJnQ6hqwm07qTMeCTH7+4jS2VVQFXY6IyF7F00fwayDPzG6K3UHUt9a2WQmtrgFLS47wh3N7UbJxO39+c27Q5YiI7FU8TUO/BB4H8oB84O9m9otEF9YYHN2+OZcc3YZHxy1iWklp0OWIiOxRPE1D3wKOcvdfx64OBgKXJbasxuOnp3UlLyuN7/1zEov15LGI1EPxBMEKIL3Wchqgx2fjlJORwl8v7sO6LRWccc9/eXFSSdAliYh8QTxBUArMMLPHzOzvwHRgk5ndY2b3JLa8xmFwx3xeu/k4urfK4fv/nMKPR02huibUUzqISD0Sz3DSL8ZeO72XmFIat1a5GTx9zQD+/NZc7n93AXlZafzk1K5BlyUisv8gcPfHzSwVODy2as7OW0jlwCRHkrjllK5s3FbJA+8toGuLbM7uUxR0WSIScvsNAjMbQvSuocVE5ypubWbfdvexiS2t8br1G92Zv2YLPx41lfb5mfQqzg26JBEJsXj6CO4CTnb34939a8ApwJ8TW1bjlpqcxAPD+pKflcbwJyayaVtF0CWJSIjFEwQp7j5n54K7zwVSEldSOORlpfHQZf1Yu6Wc28fouTwRCU48QTDRzB4xsyGx18PAhEQXFgY9inIY/rUO/GtiCePmrQu6HBEJqXiC4FpgJnBT7DUTuC6RRYXJzSd1pn1+Jv/74jS2V2jYahGpe/sMAjOLAFPc/W53Pzf2+rO7l9dRfY1eekqEP57bk6UbtnHXG3P2/wMiIofYPu8acvdqM5tjZm3cfWldFRU2AzrkcemANjwybhGvTF1Jv7bNOLZzPhf1b01SkiaEE5HEiueBsmZEnyz+FNg1WI67n5WwqkLoV2d244gW2YxfvJGJSzYyZtpKstKS+UbvVkGXJiKNXDxB8MuEVyGkp0S4bFA7LhvUjpoaZ8id7/GPj5coCEQk4eLpLD7d3d+v/QJOT3RhYZaUZFw6oA2fLNrAvNWbgy5HRBq5eIJg6B7WnXaoC5EvuqBfMamRJJ76RF0zIpJYew0CM7vOzKYBXcxsaq3XImBaPB9uZqfGOpvnm9lP97C9rZm9Hfvc98ys+KsfSuOSl5XGaT1b8PzEEk11KSIJta8rgqeBbwCjY//ufPVz92H7++DYraf3E7166AZcYmbddtvtTuAJd+8F/Ab4wwEfQSP2rYFt2VxexejJK4IuRUQasb0GgbuXuvtid78EKAEqAQeyzKxNHJ99NDDf3Re6ewXwLHD2bvt0A96JvX93D9tDrX/bZnQpzFbzkIgkVDyjj94A3AqsBmpiqx3otZ8fLQKW1VouAQbsts8U4Fzgr8A5QLaZ5bn7+v1WHgJmxrCBbfjVyzM45o/v0CQ1Qk5GCjd/vTPHdS4IujwRaSTiuX30e0CXBP1y/hFwn5ldAYwlOgXml8ZZMLPhwHCANm3iuRhpPC7o15qSjdtZv6WCbRVVzFxZxhV/H89tZ3XnWwPbBl2eiDQC8QTBMqLTVR6o5UDrWsvF7DbXsbuvIHpFgJllAee5+6bdP8jdRwAjAPr37x+qOR4zUiP87+lH7FreUl7FjU9/xi9ems7CtVv5+RlHENHTxyJyEOIJgoXAe2Y2Btg1xpC7372fnxsPdDaz9kQD4GLg0to7mFk+sMHda4CfASMPoPZQykpL5uHL+/O7MbMY+cEiqmtquO3sHkGXJSINWDxBsDT2So294uLuVbH+hf8AEWCku88ws98AE9x9NDAE+IOZOdGmoesPsP5QSo4kcetZ3YkkGY+OW0TP4lzO76c7b0XkqzH3A29pMbNkdw/k5vb+/fv7hAmaDgGgqrqGy0d+yoQlG3n+2sH0LM4JuiQRqafMbKK799/Ttn09UDau1vsnd9v86SGqTQ5CciSJey85koKsNK79x0T+NWEZD72/gDten83MFWVBlyciDcS+moYya73fvRFavZP1RF5WGg9+qx8XPPQht4yaumv9qIklvH7zceRlpQVYnYg0BPsKAt/L+z0tS4B6FufwwU9OZEt5FXlZaSzbsI2z7/+AW0ZN5dFv98dMuS0ie7evISZyzewcMzsv9v7c2Os8QI3R9UxeVhpt8zLJSkvmiJZN+dlpXXln9hqe+GgJABu2VvDw2IW8PWt1wJWKSH2zryuC94Gzar3/Rq1tYxNWkRwSVwxux9i5a7n91VlMWrqRV6evoqKqhpyMFD786YlkpsVzw5iIhMFefxu4+5V1WYgcWmbG/13Qm9P++l/+M2M1F/Qrpl/bZvzguSk88+lSrj6uQ9Alikg9oT8LG7H8rDTe+N7XSI4Y2ekpADw7fhmPjlvE5YPakZocz3QUItLY6TdBI9csM3VXCABcN6QjK0t3MHqKhrYWkSgFQcgMObyAri2yeej9BdTU6OYvEYkjCMzsAjPLjr3/hZm9YGZ9E1+aJIKZce3xHZm3ZgvvzF4TdDkiUg/E00fwS3f/l5kdC3wd+D/gAb48t4A0EGf2asmdb8zhmicnkJ4cIS0liaPbNef+YX1JiegiUSRs4vl//c75Ac4ARrj7GA5g8Dmpf5IjSdx3aV9uPKETlw1qy0ldC3lj5mrufGNO0KWJSADiuSJYbmYPAUOBO8wsDfUtNHh9WufSp3XuruW0lCQeen8hgzvmc/zhmv1MJEzi+YV+IdGhpE+JTRrTHLgloVVJnfvVmd04vDCLHz43mTWbdwRdjojUoXiCoCUwxt3nmdkQ4AI0+mijk54S4b5L+7KlvIprnpjI27NWU1lds/8fFJEGL54geB6oNrNORKeLbA08ndCqJBCHF2Zzx3m9WLJ+K1c9PoGjb3+L374ykx2VX5pGWkQakXj6CGpis42dC9zr7vea2aREFybBOLtPEaf1aMnYuWt5afJyRn6wiPGLN/Dw5f0pbJoedHkikgDxXBFUmtklwOXAK7F1KfvYXxq41OQkvt6tkPsu7cuIy/ozf80WzrpvHFNLNgVdmogkQDxBcCUwCLjd3RfFJqPffcYyaaSGdivk+esGk5yUxIUPfcQH89cFXZKIHGL7DQJ3nwn8CJhmZj2AEne/I+GVSb1xRMumvHzDMbTLy+Q7j43/QhhMX17KH16dxduzVlOlzmWRBmm/k9fH7hR6HFhMdIrK1sC33T2QOQk0eX1w1m8pZ9gjn7Bo3VZuP6cn781ZwytTV+7anp+Vxrl9i7jxxE5fGOhORIK3r8nr4wmCicCl7j4ntnw48Iy79zvklcZBQRCsnWEwe9VmmqRGuOrY9lx5THsmLtnIqInLeGvWGk7oUsCIy/qTlKQpMkXqi30FQTx3DaXsDAEAd59rZvpzL6TystJ4+pqBvDRpOd/o3YqC7DQg2pcwtFshj3+4mF+PnsH9787nxpM6B1ytiMQjniCYaGaPAP+ILQ8D9Cd5iDXPTOU7x7bf47bLB7Vl0tKN3P3WXHoW5zCky2F1XJ2IHKh47hq6FpgJ3BR7zQSuS2RR0nCZGX84txddCrO5+dnJPDpuEe/NWUPJxm1BlyYie7HPPgIziwAz3L1r3ZW0b+ojaBiWrN/KsEc+oWTj9l3rfnxqF/5nSKcAqxIJr6/cR+Du1WY2x8zauPvSxJQnjVHbvEz+++MTWL+1goVrtzJi7AL+8uY8Tunego4FWQBUVddw279n0qs4hwv6tw64YpHwiqePoBkww8w+BbbuXOnuZyWsKmkUzIz8rDTys9Jon5/JiXe9xy9fms5TVw/AzPjdmFk8+fESUiNJ9GmdS+fC7KBLFgmluGYoS3gV0ugVZKfxk1O78ouXpvPipOVsq6jmsQ8Xc1H/1rwxcxW3jJrK89cNJqJbTkXq3F6DIDbaaKG7v7/b+mOBlXv+KZG9u/ToNjz/WQm3jp7B1opqTuhSwO/P7cngTnmxjuWFDP9ax6DLFAmdfd019BegbA/rS2PbRA5IUpJx+zd7srWimo4FmdxzyZFEkoyzerfi5G6F3PnGXBas3RJ0mSKhs68gKHT3abuvjK1rl7CKpFHr1qopL19/DP8cPmjXMBRmxu/O6UFGSoRLH/6YlycvZ39PvIvIobOvIMjdx7aMQ12IhEePohyaZaZ+Yd1h2en846oBHJadzs3PTuaiER/zycL1miVNpA7s9TkCM3sGeMfdH95t/dXAUHe/qA7q+xI9R9C4Vdc4z01Yxp9en83GbZVkpkYY0CGPM3u15JwjizD7vDN5R2U167dWUJSrv0tE9ucrDTpnZoXAi0AFMDG2uj+QCpzj7qsSUOt+KQjCoWxHJR/MW8cHC9Yxbt46Fq/fxtBuhdxxXi+aZ6by7pw1/Orl6azctIN7LzmS03q2DLpkkXrtYEcfPQHoEVuc4e7vHMAXnwr8FYgAj7j7H3fb3oboENe5sX1+6u6v7uszFQThU1Pj/P3Dxdzx2mxym6TQu3Uub85cTceCTLLSU5i+vJS7L+zN2X2KAJhasokpyzZxydFtSI7EM4qKSON3UEFwEF8aAeYCQ4ESYDxwSWyim537jAAmufsDZtYNeNXd2+3rcxUE4TVjRSk3PzuZpRu2ceMJnRh+fAeqqp2rH5/Ax4vWc+Xg9ny6eD3Tl0dvdrv2+I789LR6MzqKSKAOdhjqr+poYL67L4wV8SxwNtFB63ZyoGnsfQ6wIoH1SAPXvVUOr950HFvKq2ge62xOS4a/X3kUw5+cyMgPFtG1RTa/Pbs705eX8eD7C+jXthlDuxUGXLlI/ZbIICgCltVaLgEG7LbPrcAbZnYjkAl8fU8fZGbDgeEAbdq0OeSFSsORmpxE8+Qv3nGUnhLh0W/3Z/G6rXQ6LAszY0dlNTNWlvLD5yYz5qbjaN28SUAVi9R/QTegXgI85u7FwOnAk2b2pZrcfYS793f3/gUFBXVepNR/KZEkOhdm77qrKD0lwgPDopPoXffURMqrqoMsT6ReS2QQLCc6v/FOxbF1tV0FPAfg7h8B6UB+AmuSEGndvAl3XdiH6cvLuOfteUGXI1JvJTIIxgOdzay9maUCFwOjd9tnKXASgJkdQTQI1iawJgmZod0KOb9fMQ++v5BpJaW71k8t2cRJd73H/e/Op7pGTzFLuCUsCNy9CrgB+A8wC3jO3WeY2W/MbOcQ1j8ErjGzKcAzwBWusQXkEPvlGd3Iy0zlllFTqKiqYfryUr71yCesLN3B//1nDpeP/IQ1ZTuCLlMkMAm7fTRRdPuofBVvzlzNNU9M4Ly+xbw9ezWZqck8O3wgHy5Yx69HzyAzNZlhA9tyXOd8+rTOJUXPH0gjE8hzBImiIJCv6uZnJ/Hy5BW0zEnnn8MH0SYveifRvNWb+cVL0xm/eAM1DpmpEW45pQtXHNM+4IpFDp2gniMQqVduO6s7eZlpXD6o7a4QAOhcmM0/vzuI0m2VfLRwPU9/upRb/z2TpCTj8kHtgitYpI7oikBkN5XVNVz3j894a9Zq7jivJxcd1QZ3Z83mcrZVVJOcZKREkijITtOMatJgqGlI5ACVV1Uz/ImJjJ23li6F2SzdsI1tFV98FqFvm1yevmYg6SmRgKoUiZ+ahkQOUFpyhIcu68eto2ewumwHgzrm0T4/k+z0ZKqqnVWlO7jrzbn87wvTuOvC3pgZ2yuq+cFzk5m8bBNXDG7HJQPa0DQ2+Y5IfaYgENmL9JQIfzyv1163O3D3m3PpXpTDOUcWcdXj45m8bBO9inP5w2uzufed+VwxuB03ntSJtGRdNUj9pSAQ+YpuOKETM1eU8ftXZzFy3CLWbSnngWF9ObVHS6YvL+WB9xdw37vzeX/uWu679Eja5mUGXbLIHulmaZGvKCnJuPPC3nQqyGJrRRVPXT2AU3tEJ8jpUZTD/Zf2ZcRl/Viyfitn3jOOMVNXBlyxyJ7pikDkIGSlJfPi9YOpqKoht0nql7af3L0Fr7Zqyo3PTOL6pz9j0/YeDBvQNoBKRfZOVwQiB6lJavIeQ2Cn4mZNeHb4QE7sehg/f3E6z3y6dI/7fbpoA7eOnsH6LeWJKlVkj3RFIFIH0pIjPPCtvnz3yYn87IVplFdWM7hTPunJEVaWbufed+Yzbv46AMq2V3L3RX0CrljCREEgUkfSkiM8+K1+DH9yIrf+e+YXtuVlpvKLM45gddkOHv7vIi48qjUDO+R96TMqqmp4/rMSehfn0q1V0y9tF/kqFAQidSg9JcIjl/fnwwXr2FJexY7KGpKTjJO7F9IkNZntFdW8Om0Vv3xpOq/efNwXBr+btHQjP3l+KnNXb8EMLj6qNT88uQv5WWkBHpE0BgoCkTqWmpzEkC6H7XFbRmqE287qztVPTGDkuEVcc1wHpq8oZdTEEp78eAktmqZz/6V9+WzpRh7/cDGvTFnJ3Rf10bzMclA0xIRIPXT14+MZN38dTdNTWLO5nCSDSwe04SendiU79rTygrVbuPHpSawu28E7PxxCTpP9P8U8b/Vmlm/azvGHF+ya1lPCQWMNiTQwyzZs45onJtDxsCxO6noYQ7ocRvPML9+ZNGNFKd+4dxzDBrTlt9/ssc/PHDt3Ldf+YyLbKqoZ2KE5vzqzu/oZQkRBINKI3Tp6Bo9/tJjR1x9Lz+IcNm6t4I7XZ7OlvIpz+xbxtc4FvDJ1JT/61xQ6F2ZzXt8i7nt3PmXbK7n6uA787LSuujoIAQ06J9KIfX/o4bwydSW/fHk6Pxh6OLeMmsKGrRVkp6fwytSV5GWmsn5rBYM65PHQ5f1omp7C+f2KuX3MLEaMXUiPohzO6t0q6MOQAOmKQKQReOGzEn7w3BQAOh2WxV8u6sPhhdm8N2cNz39WQrMmqdx2dvcvDH5XXeOc+8CHLF2/lTd/cLzuPmrk1DQk0si5Oz95fipZaSncckoXMlLjG+107urNnHnPOIZ2L+T+S/smuEoJkpqGRBo5M+NP5/c+4J87vDCbm07qxJ1vzOWU7ivoWZTDyk3b2bS9ktyMFJplptIkNcKGrRWs3VxOZbUztFshqckanaYxURCIhNx3j+/Ia9NXcdMzk+Lav1/bZvxtWF8Km6YnuDKpKwoCkZBLiSTxwLB+vDJtBYXZ6bTMTadZk1RKt1eycWsFW8qryMtKpSArnXlrNvPzF6dz5r3j+NuwvhzVrnnQ5cshoD4CETkgc1Zt5rtPTmDphm20zcukKDeDNnlNuOa4DrTP1+Q79dW++gjU0CciB6RLi2xevuFYbjihE91aNWVzeRUvTVrOOX/7gE8Xbdi139uzVnPiXe9x4UMfMXrKCiqqagKsWvZFVwQictCWrN/KlY+Np2TDdn5zdncmLNnIqIkldD4si/KqGpZu2EZ+VirDv9aBK49p/4XB9KRu6PZREUm4Tdsq+O6TE/lk0QYiScZ1x3fkxpM6kZKUxNh5axn5wWLGzl3LES2b8vtzelDULIMXP1vOC58tJz01wvVDOjK0W6Geck4QBYGI1Inyqmoe+2Axgzvm07M450vb/zNjFb9+eQarN+8gyYzqGqdf22as21LOkvXb6FHUlJtO7MzXjygkKenzQHB33PnCOjkwCgIRqTc276jk4bELqapxzutXTMeCLKqqa3hx0nLufWc+Szdso/NhWQz/Wge6t8phzLQVvDx5BRu3VnDt8R25+rgOcT8wJ59TEIhIg1BZXcOYqSt58P0FzF61GYBIknFsp3xSIkm8NWs1hU3T+OHQLpzfr1hXCAdAQSAiDYq7M3beOg0dqugAAAplSURBVFZs2s7XjyikIDs6DtL4xRv4/auzmLR0E/3bNuMP5/akc2F2wNU2DAoCEWk03J1RE0u4/dVZbC2v4jvHtufkboV0b5VDWnISs1ZuZsy0FUxcspEzerXiov6tNSQGCgIRaYTWbynnd2Nm8eKk5QCkRIz8rDRWlu4gkmS0ad6EReu2Utwsg2uP70gkyZi3egtL1m8lJyOF4uZNaN0sg5O7tyAnY/+zuzV0CgIRabTWbi7ns6UbmbR0E0vWb+WYTvmc1qMFzTNTGTtvHXe9MYepJaUApKck0S4vk7Ltlawq20GNQ4eCTJ74ztEUN2sS8JEkVmBBYGanAn8FIsAj7v7H3bb/GTghttgEOMzdc/f1mQoCETkQ7s705WXkNkmhKDdjVwdzRVUNnyxaz/VPfUZ6SoTHv3M0R7RsyvaKaiYt3ci8NVtYsn4byzZu47jO+Vw+qF2wB3KQAgkCM4sAc4GhQAkwHrjE3WfuZf8bgSPd/Tv7+lwFgYgcSnNWbebbIz9la3kVnQuzmLa8lMrq6O/FjJQIzZqksKJ0B7/9Zg8uG9g24Gq/uqDmIzgamO/uC2NFPAucDewxCIBLgF8nsB4RkS/p0iKbF/5nMD94bjIVVTVcdWwHBnRoTveWTSnITqO6xrn2HxP51cvTKchK49QeLYIu+ZBL5BXB+cCp7n51bPkyYIC737CHfdsCHwPF7l69h+3DgeEAbdq06bdkyZKE1CwisifbK6q59JGPmbGijN+d3YP87FSSzOiQn0WbvD33LazYtJ1nxy9jzqoyfnt2Dw6rNX9DTY0za1UZ3Vo2rbMhNRrCDGUXA6P2FAIA7j4CGAHRpqG6LExEJCM1wshvH8X5D37Ij5+fumt9cpJx00mduW5IR1IiSbg7/523jic+Wsw7s9fgROd7uGjExzx19QBa5WZQtqOS7z87mbdnr+GygW257azugT8Yl8ggWA60rrVcHFu3JxcD1yewFhGRg9IsM5UxNx3HvNVbqHanuqaGxz9cwt1vzuXNmav55pFFPPvpUuat2UJ+VirXDenIxUe1Yc3mHVwxcjwXPvQRt5/Tk9v+PYMl67dxQpcCnvx4CVU1Ndz+zZ77DYOKqhoqq2vITDv0v7YT2TSUTLSz+CSiATAeuNTdZ+y2X1fgdaC9x1GMOotFpD55bdpKfv7SdDZsraB7q6ZcdWx7zujVkrTkz8dDmlqyicse/ZTS7ZU0z0zlb8P6MqB9c+56Yy73vTufc48s4vguBWzaVknZ9kraF2RyZJtmtMpJZ+bKMkZNLOHlySu4cnA7bjyp81eqM5CmIXevMrMbgP8QvX10pLvPMLPfABPcfXRs14uBZ+MJARGR+ua0ni0Z1DGPlaU76Noie49t/r2Kc3l2+ECe+GgJN5zYiaLcDAB+dEoXUiJJ/Pmtubww6csNJk3TkynbUUVqJImh3Qo5un1ipgbVA2UiIgGbv2YL4DRrkkpmWjLzVm9h0rKNzFheRveippzVuxW5TVIP6jsaQmexiEhodTos6wvLPYtz9jifQ6JoJCYRkZBTEIiIhJyCQEQk5BQEIiIhpyAQEQk5BYGISMgpCEREQk5BICIScg3uyWIzWwt81XGo84F1h7CchiKMxx3GY4ZwHncYjxkO/LjbunvBnjY0uCA4GGY2YW+PWDdmYTzuMB4zhPO4w3jMcGiPW01DIiIhpyAQEQm5sAXBiKALCEgYjzuMxwzhPO4wHjMcwuMOVR+BiIh8WdiuCEREZDcKAhGRkAtNEJjZqWY2x8zmm9lPg64nEcystZm9a2YzzWyGmd0cW9/czN40s3mxf5sFXWsimFnEzCaZ2Sux5fZm9knsnP/TzA5uiqd6xsxyzWyUmc02s1lmNigM59rMvh/773u6mT1jZumN8Vyb2UgzW2Nm02ut2+P5tah7Ysc/1cz6Hsh3hSIIzCwC3A+cBnQDLjGzbsFWlRBVwA/dvRswELg+dpw/Bd52987A27HlxuhmYFat5TuAP7t7J2AjcFUgVSXOX4HX3b0r0JvosTfqc21mRcBNQH9370F0PvSLaZzn+jHg1N3W7e38ngZ0jr2GAw8cyBeFIgiAo4H57r7Q3SuAZ4GzA67pkHP3le7+Wez9ZqK/GIqIHuvjsd0eB74ZTIWJY2bFwBnAI7FlA04ERsV2aVTHbWY5wNeARwHcvcLdNxGCc010it0MM0sGmgAraYTn2t3HAht2W72383s28IRHfQzkmlnLeL8rLEFQBCyrtVwSW9domVk74EjgE6DQ3VfGNq0CCgMqK5H+AvwYqIkt5wGb3L0qttzYznl7YC3w91hz2CNmlkkjP9fuvhy4E1hKNABKgYk07nNd297O70H9jgtLEISKmWUBzwPfc/ey2ts8er9wo7pn2MzOBNa4+8Sga6lDyUBf4AF3PxLYym7NQI30XDcj+tdve6AVkMmXm09C4VCe37AEwXKgda3l4ti6RsfMUoiGwFPu/kJs9eqdl4mxf9cEVV+CHAOcZWaLiTb7nUi0/Tw31nwAje+clwAl7v5JbHkU0WBo7Of668Aid1/r7pXAC0TPf2M+17Xt7fwe1O+4sATBeKBz7M6CVKKdS6MDrumQi7WLPwrMcve7a20aDXw79v7bwMt1XVsiufvP3L3Y3dsRPbfvuPsw4F3g/Nhujeq43X0VsMzMusRWnQTMpJGfa6JNQgPNrEnsv/edx91oz/Vu9nZ+RwOXx+4eGgiU1mpC2j93D8ULOB2YCywAfh50PQk6xmOJXipOBSbHXqcTbS9/G5gHvAU0D7rWBP5vMAR4Jfa+A/ApMB/4F5AWdH2H+Fj7ABNi5/sloFkYzjVwGzAbmA48CaQ1xnMNPEO0H6SS6BXgVXs7v4ARvTNyATCN6F1VcX+XhpgQEQm5sDQNiYjIXigIRERCTkEgIhJyCgIRkZBTEIiIhJyCQCTGzKrNbHKt1yEbsM3M2tUeRVKkPkne/y4iobHd3fsEXYRIXdMVgch+mNliM/uTmU0zs0/NrFNsfTszeyc2/vvbZtYmtr7QzF40symx1+DYR0XM7OHYWPpvmFlGbP+bYnNITDWzZwM6TAkxBYHI5zJ2axq6qNa2UnfvCdxHdKRTgHuBx929F/AUcE9s/T3A++7em+j4PzNi6zsD97t7d2ATcF5s/U+BI2Ofc22iDk5kb/RksUiMmW1x96w9rF8MnOjuC2OD+q1y9zwzWwe0dPfK2PqV7p5vZmuBYncvr/UZ7YA3PTqhCGb2EyDF3X9nZq8DW4gOE/GSu29J8KGKfIGuCETi43t5fyDKa72v5vM+ujOIjhPTFxhfaxRNkTqhIBCJz0W1/v0o9v5DoqOdAgwD/ht7/zZwHeyaRzlnbx9qZklAa3d/F/gJkAN86apEJJH0l4fI5zLMbHKt5dfdfectpM3MbCrRv+ovia27kegMYbcQnS3sytj6m4ERZnYV0b/8ryM6iuSeRIB/xMLCgHs8OuWkSJ1RH4HIfsT6CPq7+7qgaxFJBDUNiYiEnK4IRERCTlcEIiIhpyAQEQk5BYGISMgpCEREQk5BICIScv8PoQK6uOA3f7YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1DwrV5CAUSD"
      },
      "source": [
        "## Saving model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPBs735K9RTj"
      },
      "source": [
        "torch.save(few_shot_classifier.state_dict(), \"/content/drive/MyDrive/MiniImageNet/MiniImagenet/clas_stage2_attn_0.0001.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMp4y3pCAv3K"
      },
      "source": [
        "## Evaluating base class accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teGMQVBHAmnT"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/MiniImageNet/MiniImagenet/miniImageNet_category_split_train_phase_val.pickle\", 'rb') as f:\n",
        "      validation_data = pickle.load(f, encoding='latin1')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vqhns61Rkyi"
      },
      "source": [
        "BATCH_SIZE=8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKLNZXMRArDL"
      },
      "source": [
        "val_data = MiniImageNet(validation_data)\n",
        "val_dataloader = data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoXODePe8m_D"
      },
      "source": [
        "base_classifier = Classifier().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_GUmCSj8rYm",
        "outputId": "1566eb33-cd3b-400a-bd1e-6c0c6a184c08"
      },
      "source": [
        "base_classifier_dict = base_classifier.state_dict()\n",
        "few_shot_classifier_wts = torch.load('/content/drive/MyDrive/MiniImageNet/MiniImagenet/clas_stage2_attn_0.0001.pth')\n",
        "modified_state_dict = {}\n",
        "for k in base_classifier_dict.keys():\n",
        "  if k in few_shot_classifier_wts.keys():\n",
        "    modified_state_dict[k] = few_shot_classifier_wts[k]\n",
        "  else:\n",
        "    modified_state_dict[k] = base_classifier_dict[k]\n",
        "modified_state_dict = collections.OrderedDict(modified_state_dict)\n",
        "base_classifier_dict.update(modified_state_dict)\n",
        "base_classifier.load_state_dict(base_classifier_dict)\n",
        "base_classifier.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight_base',\n",
              "              tensor([[ 0.0919,  0.1499,  0.0825,  ...,  0.0016, -0.0138,  0.0282],\n",
              "                      [ 0.0882,  0.0779,  0.0135,  ..., -0.0295, -0.0274, -0.0244],\n",
              "                      [ 0.0169,  0.0320,  0.0608,  ...,  0.1098,  0.1522, -0.0396],\n",
              "                      ...,\n",
              "                      [-0.0844, -0.1494, -0.1572,  ...,  0.0526, -0.0098,  0.0527],\n",
              "                      [-0.0111,  0.1204,  0.0740,  ...,  0.0536,  0.1448,  0.1783],\n",
              "                      [ 0.0128,  0.0542,  0.0665,  ...,  0.0023,  0.0281, -0.0064]],\n",
              "                     device='cuda:0')),\n",
              "             ('bias', tensor([-2.9767], device='cuda:0')),\n",
              "             ('scale_cls', tensor([45.0475], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eMmE0A5Audx",
        "outputId": "9bba60c8-3ffc-483f-9639-90bdf3706620"
      },
      "source": [
        "feature_extractor.eval()\n",
        "acc = 0\n",
        "cnt = 0\n",
        "for X,Y in val_dataloader:\n",
        "  X = X.to(device)\n",
        "  Y = Y.to(device)\n",
        "  output = base_classifier(feature_extractor(X))\n",
        "  pred  = torch.argmax(output.view(8,64),dim=1)\n",
        "  acc += skm.accuracy_score(Y.cpu().detach().numpy(),pred.cpu().detach().numpy())\n",
        "  cnt += 1\n",
        "\n",
        "print('Base class accuracy: ', acc/cnt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base class accuracy:  0.6286979166666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRe1cWMmA0iA"
      },
      "source": [
        "## Evaluating novel class accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4FGwz17qmex"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/MiniImageNet/MiniImagenet/miniImageNet_category_split_val.pickle\", 'rb') as f:\n",
        "      novel_validation_data = pickle.load(f, encoding='latin1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZV0VBZcgPib"
      },
      "source": [
        "val_data_novel = MiniImageNet(data_base=validation_data, data_novel=novel_validation_data, phase='val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC7rMkD-hB1-"
      },
      "source": [
        "val_novel_dataloader = FewShotDataloader(\n",
        "    val_data_novel, \n",
        "    nKnovel=5, \n",
        "    nKbase=0, # Novel class alone\n",
        "    nExemplars=5, \n",
        "    nTestNovel=75, \n",
        "    nTestBase=0, \n",
        "    batch_size=1, \n",
        "    epoch_size=200\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clPaszl712qk"
      },
      "source": [
        "BATCH_SIZE=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-1SKc3XjWGL",
        "outputId": "c2d506b7-316b-4a1c-c4e2-56762b0839d3"
      },
      "source": [
        "feature_extractor.eval()\n",
        "acc = 0\n",
        "cnt = 0\n",
        "for Xe,Ye,Xt,Yt,Kall,nKbase in val_novel_dataloader():\n",
        "    Xe = Xe.to(device).view(1 * 25, 3, 84, 84)\n",
        "    features_train = feature_extractor(Xe)\n",
        "    features_train = features_train.resize(1,25,3200)\n",
        "    del Xe\n",
        "\n",
        "    Xt = Xt.to(device).view(1 * 75, 3, 84, 84)\n",
        "    features_test = feature_extractor(Xt)\n",
        "    features_test = features_test.resize(1,75,3200)\n",
        "    Ye = torch.tensor(Ye).to(device)\n",
        "    labels_train = []\n",
        "\n",
        "    for labels in Ye:\n",
        "      enc = OneHotEncoder()\n",
        "      labels_train.append(enc.fit_transform(labels.cpu().numpy().reshape(-1,1)).toarray())\n",
        "\n",
        "    labels_train = torch.tensor(labels_train).to(device)\n",
        "\n",
        "    output = few_shot_classifier(features_test, features_train.float(), labels_train.float(), Kbase_ids=None, batch_size=1)\n",
        "    \n",
        "    Yt = torch.tensor(Yt).to(device).view(1*75)\n",
        "    #print(output.size())\n",
        "    pred  = torch.argmax(output[:,:,64:].view(75,5),dim=1)\n",
        "    acc += skm.accuracy_score(Yt.cpu().detach().numpy(),pred.cpu().detach().numpy())\n",
        "    cnt += 1\n",
        "\n",
        "print('Novel class accuracy: ', acc/cnt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Novel class accuracy:  0.6916666666666663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLIEGTzS85w9"
      },
      "source": [
        "## Evaluating both base and novel accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qczUNEpB8816"
      },
      "source": [
        "val_both_dataloader = FewShotDataloader(\n",
        "    val_data_novel, \n",
        "    nKnovel=5, \n",
        "    nKbase=64, \n",
        "    nExemplars=5, \n",
        "    nTestNovel=75, \n",
        "    nTestBase=75, \n",
        "    batch_size=1, \n",
        "    epoch_size=200\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3DpDYVD9IK2",
        "outputId": "42ac9ada-bbd9-47ca-91bc-51d963a2b695"
      },
      "source": [
        "feature_extractor.eval()\n",
        "acc = 0\n",
        "cnt = 0\n",
        "for Xe,Ye,Xt,Yt,Kall,nKbase in val_both_dataloader():\n",
        "    Xe = Xe.to(device).view(1 * 25, 3, 84, 84)\n",
        "    features_train = feature_extractor(Xe)\n",
        "    features_train = features_train.resize(1,25,3200)\n",
        "    del Xe\n",
        "\n",
        "    Xt = Xt.to(device).view(1 * 150, 3, 84, 84)\n",
        "    features_test = feature_extractor(Xt)\n",
        "    features_test = features_test.resize(1,150,3200)\n",
        "    Ye = torch.tensor(Ye).to(device)\n",
        "    labels_train = []\n",
        "\n",
        "    for labels in Ye:\n",
        "      enc = OneHotEncoder()\n",
        "      labels_train.append(enc.fit_transform(labels.cpu().numpy().reshape(-1,1)).toarray())\n",
        "\n",
        "    labels_train = torch.tensor(labels_train).to(device)\n",
        "\n",
        "    output = few_shot_classifier(features_test, features_train.float(), labels_train.float(), Kbase_ids=None, batch_size=1)\n",
        "    \n",
        "    Yt = torch.tensor(Yt).to(device).view(1*150)\n",
        "    #print(output.size())\n",
        "    pred  = torch.argmax(output.view(150,69),dim=1)\n",
        "    acc += skm.accuracy_score(Yt.cpu().detach().numpy(),pred.cpu().detach().numpy())\n",
        "    cnt += 1\n",
        "\n",
        "print('Both base and novel class accuracy: ', acc/cnt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Both base and novel class accuracy:  0.5439000000000004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7chvBiFBTCnP"
      },
      "source": [
        "Training Stage 1 - 100 epochs, Training Stage 2 - 200 epochs\n",
        "\n",
        "* **Base class accuracy**:  61.19%\n",
        "* **Novel class accuracy**:  66.14%\n",
        "* **Both base and novel class accuracy**:  50.22%\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXJYKhWjwL-2"
      },
      "source": [
        "Training Stage 1 - 100 epochs, Training Stage 2 - 10 epochs [Attn]\n",
        "\n",
        "\n",
        "*   Base Class accuracy: 62\n",
        "*   Novel : 66\n",
        "*   Both : 50.93\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YJf9HfpHz8G"
      },
      "source": [
        "Train Stage 2 100 attn\n",
        "both: 52"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C6hchUql1Pc"
      },
      "source": [
        "Train Stage 1 (0.0001) 100 epochs Stage 2 100 epochs\n",
        "Base: 63\n",
        "Novel: 69\n",
        "Both: 54"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0kpRhZATb0-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}